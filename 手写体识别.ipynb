{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 加载必要的库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets,transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 定义超参数\n",
    "BATCH_SIZE = 16 # 每批处理的数据\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # 是否使用GPU\n",
    "EPOCHS = 10 #训练数据集的轮次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 构建pipeline，对图像进行处理\n",
    "pipline = transforms.Compose([\n",
    "    transforms.ToTensor(), # 将图片转换成tensor\n",
    "    transforms.Normalize((0.1307,),(0.3081,1)) # 标准化：降低模型复杂度\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 下载，加载数据\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 下载数据集\n",
    "#train_set = datasets.MNIST(\"data\", train=True, download=True, transform=pipline)\n",
    "\n",
    "train_set = datasets.MNIST(\n",
    "    root=\"./mnist\",\n",
    "    train=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=False\n",
    ")\n",
    "\n",
    "#test_set = datasets.MNIST(\"data\", train=False, download=True, transform=pipline)\n",
    "test_set = datasets.MNIST(\n",
    "    root=\"./mnist\",\n",
    "    train=False,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=False\n",
    ")\n",
    "\n",
    "#加载数据\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 构建网络模型\n",
    "class Digit(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1,10,5) # 1:灰度图片的通道， 10：输出通道， 5：kernel\n",
    "        self.conv2 = nn.Conv2d(10,20,3) # 10:输入通道， 20：输出通道， 3：kernel\n",
    "        self.fc1 = nn.Linear(20*10*10,500) # 20*10*10：输入通道， 500：输出通道\n",
    "        self.fc2 = nn.Linear(500,10) # 500：输入通道 10：输出通道\n",
    "        \n",
    "    def forward(self,x):\n",
    "        input_size = x.size(0) #batch_size\n",
    "        x = self.conv1(x) #输入：batch*1*28*28，输出：batch*10*24*24 （28-5+1=24）\n",
    "        x = F.relu(x) # 保持shape不变，输出：batch*10*24*24 \n",
    "        x = F.max_pool2d(x,2,2) #输入： batch*10*24*24 输出：batch*10*12*12\n",
    "        \n",
    "        x = self.conv2(x) # 输入： batch*10*12*12 输出：batch*20*10*10  (12-3+1=10)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = x.view(input_size,-1) # 拉平，-1 自动计算维度，20*10*10= 2000\n",
    "        \n",
    "        x = self.fc1(x) # 输入： batch*2000 输出：batch*500\n",
    "        x = F.relu(x) # 保持shape不变\n",
    "        \n",
    "        x = self.fc2(x) # 输入： batch*500 输出：batch*10\n",
    "        \n",
    "        output = F.log_softmax(x,dim=1) # 计算分类后，每个数字的概率值\n",
    "        \n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 定义优化器\n",
    "model = Digit().to(DEVICE)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 定义训练方法\n",
    "def train_model(model,device,train_loader,optimizer,epoch):\n",
    "    #模型训练\n",
    "    model.train()\n",
    "    for batch_index,(data,target) in enumerate(train_loader):\n",
    "        #部署到DEVICE上去\n",
    "        data,target =data.to(device),target.to(device)\n",
    "        #梯度初始化为0\n",
    "        optimizer.zero_grad()\n",
    "        #训练后的结果\n",
    "        output = model(data)\n",
    "        #计算损失\n",
    "        loss = F.cross_entropy(output,target)\n",
    "        #找到概率值最大的下标\n",
    "        pred = output.max(1,keepdim=True) # pred =output.argmax(dim=1)\n",
    "        #反向传播\n",
    "        loss.backward()\n",
    "        #参数优化\n",
    "        optimizer.step()\n",
    "        if batch_index % 3000 ==0:\n",
    "            print(\"训练Epoch: {}\\t Loss:{:.6f}\".format(epoch,loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 定义测试方法\n",
    "def test_model(model,device,test_loader):\n",
    "    #模型验证\n",
    "    model.eval()\n",
    "    #正确率\n",
    "    correct = 0.0\n",
    "    #测试损失\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():#不会计算梯度，也不会进行反向传播\n",
    "        for data,target in test_loader:\n",
    "            #部署到device上\n",
    "            data,target = data.to(device),target.to(device)\n",
    "            #测试数据\n",
    "            output = model(data)\n",
    "            #计算测试损失\n",
    "            test_loss += F.cross_entropy(output,target).item()\n",
    "            #找到概率值最大的下标\n",
    "            pred = output.max(1,keepdim=True)[1] #值，索引\n",
    "            #pred = torch.max(output,dim=1)\n",
    "            #pred = output.argmax(dim=1)\n",
    "            #累计正确率\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        print(\"Test --- Average loss : {:.4f},Accuracy:{:3f}\\n\".format(\n",
    "            test_loss,100.0*correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练Epoch: 1\t Loss:2.306225\n",
      "训练Epoch: 1\t Loss:0.001202\n",
      "Test --- Average loss : 0.0032,Accuracy:98.250000\n",
      "\n",
      "训练Epoch: 2\t Loss:0.278720\n",
      "训练Epoch: 2\t Loss:0.570541\n",
      "Test --- Average loss : 0.0028,Accuracy:98.580000\n",
      "\n",
      "训练Epoch: 3\t Loss:0.001264\n",
      "训练Epoch: 3\t Loss:0.011902\n",
      "Test --- Average loss : 0.0018,Accuracy:98.970000\n",
      "\n",
      "训练Epoch: 4\t Loss:0.000558\n",
      "训练Epoch: 4\t Loss:0.004187\n",
      "Test --- Average loss : 0.0019,Accuracy:99.090000\n",
      "\n",
      "训练Epoch: 5\t Loss:0.000019\n",
      "训练Epoch: 5\t Loss:0.000116\n",
      "Test --- Average loss : 0.0031,Accuracy:98.870000\n",
      "\n",
      "训练Epoch: 6\t Loss:0.000011\n",
      "训练Epoch: 6\t Loss:0.000782\n",
      "Test --- Average loss : 0.0025,Accuracy:98.900000\n",
      "\n",
      "训练Epoch: 7\t Loss:0.021214\n",
      "训练Epoch: 7\t Loss:0.035395\n",
      "Test --- Average loss : 0.0030,Accuracy:98.910000\n",
      "\n",
      "训练Epoch: 8\t Loss:0.000003\n",
      "训练Epoch: 8\t Loss:0.000093\n",
      "Test --- Average loss : 0.0028,Accuracy:98.930000\n",
      "\n",
      "训练Epoch: 9\t Loss:0.000004\n",
      "训练Epoch: 9\t Loss:0.000018\n",
      "Test --- Average loss : 0.0029,Accuracy:99.050000\n",
      "\n",
      "训练Epoch: 10\t Loss:0.000024\n",
      "训练Epoch: 10\t Loss:0.000400\n",
      "Test --- Average loss : 0.0037,Accuracy:98.870000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 9 调用 方法7/8\n",
    "for epoch in range(1,EPOCHS + 1):\n",
    "    train_model(model,DEVICE,train_loader,optimizer,epoch)\n",
    "    test_model(model,DEVICE,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
